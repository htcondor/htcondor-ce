
###############################################################################
#
# HTCondor-CE JobRouter configuration
#
# DO NOT EDIT THIS FILE!  It will be overwritten upon RPM upgrade.
# If you wish to make changes to the HTCondor-CE configuration, create files
# in /etc/condor-ce/config.d containing your changes.
#
###############################################################################

# The below script generates proper settings for JOB_ROUTER_DEFAULTS, merged
# with OSG environment variables (if present).  Anytime you reconfig the OSG,
# you will need to reconfig HTCondor-CE
LOCAL_CONFIG_FILE = /usr/share/condor-ce/condor_ce_router_defaults|

# Set the maximum number of jobs the CE is willing to run.  Note this
# affects both GRIDMANAGER_MAX_SUBMITTED_JOBS_PER_RESOURCE (for non-HTCondor
# sites) and JOB_ROUTER_DEFAULTS
CONDORCE_MAX_JOBS = 10000
GRIDMANAGER_MAX_SUBMITTED_JOBS_PER_RESOURCE = $(CONDORCE_MAX_JOBS)

# Set the same MaxJobs/MaxIdleJobs when using the job router transform syntax
JOB_ROUTER_DEFAULT_MAX_IDLE_JOBS_PER_ROUTE = 2000
JOB_ROUTER_DEFAULT_MAX_JOBS_PER_ROUTE = $(CONDORCE_MAX_JOBS)

# Only route jobs for either the vanilla or standard universe.
JOB_ROUTER_SOURCE_JOB_CONSTRAINT = target.JobUniverse =?= 5 || target.JobUniverse =?= 1

# Put jobs on hold if they are not in the removed state and meet any of the following requirements:
# 1. It has not been routed by the CE and is not a standard, vanilla, scheduler, or local job.
HOLD_CLAUSE_1 = (RoutedBy is null && JobUniverse =!= 1 && JobUniverse =!= 5 && JobUniverse =!= 7 && JobUniverse =!= 12)
HOLD_REASON_1 = "invalid job universe."

# 2. It has not been routed by the CE and has been idle for 30+ min
HOLD_CLAUSE_2 = ((JobStatus =?= 1 && time() - EnteredCurrentStatus > 1800) && RoutedToJobId is null && RoutedJob =!= true)
HOLD_REASON_2 = "no matching routes, route job limit, or route failure threshold; see 'HTCondor-CE Troubleshooting Guide'"

SYSTEM_PERIODIC_HOLD = $(JobStatus != 3) && \
                           ($(HOLD_CLAUSE_1) || \
                            $(HOLD_CLAUSE_2))

SYSTEM_PERIODIC_HOLD_REASON = \
   strcat("HTCondor-CE held job due to ", \
            $(HOLD_CLAUSE_1) ? $(HOLD_REASON_1) : \
                               $(HOLD_REASON_2) \
          )


# Remove jobs that have been on hold for longer than 24 hrs
REMOVE_CLAUSE_1 = (JobStatus == 5 && time() - EnteredCurrentStatus > 3600*24)
REMOVE_REASON_1 = "being in the hold state for 24 hours."

# Remove routed jobs that have already started once,
# Users can allow jobs to try more than once on the batch side by setting "ENABLE_JOB_RETRIES = True"
ENABLE_JOB_RETRIES = False
REMOVE_CLAUSE_2 = ((!isUndefined(RoutedtoJobId) && $(ENABLE_JOB_RETRIES) =!= True) && \
                    ((JobStatus == 1 && NumJobStarts == 1) || (NumJobStarts > 1)))
REMOVE_REASON_2 = "disabled job retries"

# Remove completed jobs that have been in that state for over 30 days
COMPLETED_JOB_EXPIRATION = 30
REMOVE_CLAUSE_3 = (JobStatus == 4 && time() - EnteredCurrentStatus > $(COMPLETED_JOB_EXPIRATION)*3600*24)
REMOVE_REASON_3 = strcat("job completed over ", $(COMPLETED_JOB_EXPIRATION), " days ago.")

# Remove jobs that have exceeded configured or requested max wall time
REMOVE_CLAUSE_4 = (JobUniverse == 5 && \
                   JobStatus == 2 && \
                   (time() - JobCurrentStartDate) > \
                       (maxWalltime is undefined ? (BatchRuntime is undefined ? $(ROUTED_JOB_MAX_TIME)*60 : BatchRuntime) : maxWalltime*60) )
REMOVE_REASON_4 = strcat("job exceeded allowed walltime: ", \
                         maxWalltime is undefined ? (BatchRuntime is undefined ? $(ROUTED_JOB_MAX_TIME)*60 : BatchRuntime) : maxWalltime*60, \
                         " minutes.")

SYSTEM_PERIODIC_REMOVE =  $(REMOVE_CLAUSE_1) || \
                          $(REMOVE_CLAUSE_2) || \
                          $(REMOVE_CLAUSE_3) || \
                          $(REMOVE_CLAUSE_4)

DEFAULT_REMOVE_REASON = "input files missing."

SYSTEM_PERIODIC_REMOVE_REASON = \
   strcat("CE job removed by SYSTEM_PERIODIC_REMOVE due to ", \
          $(REMOVE_CLAUSE_1) ? $(REMOVE_REASON_1) : \
          $(REMOVE_CLAUSE_2) ? $(REMOVE_REASON_2) : \
          $(REMOVE_CLAUSE_3) ? $(REMOVE_REASON_3) : \
          $(REMOVE_CLAUSE_4) ? $(REMOVE_REASON_4) : \
                               $(DEFAULT_REMOVE_REASON) \
   )

# This attribute limits the max time of any job to 72 hours.
ROUTED_JOB_MAX_TIME = 4320

# Give the job router a unique name to distinguish the HTCondor-CE jobs from
# the site JobRouter jobs.
JOB_ROUTER_NAME = htcondor-ce

# The version of the HTCondor-CE.  Useful for debugging purposes.
HTCondorCEVersion = "@HTCONDORCE_VERSION@"
grid_resource = strcat("condor ", ifThenElse(size("$(SCHEDD_NAME)") > 0, "$(SCHEDD_NAME)", "$(FULL_HOSTNAME)"), " ", "$(COLLECTOR_HOST)")
SCHEDD_ATTRS = $(SCHEDD_ATTRS) HTCondorCEVersion grid_resource

# Use the defaults generated by the condor_ce_router_defaults script.  To add
# additional defaults in the old syntax, add additional lines of the form:
#
#   JOB_ROUTER_DEFAULTS = $(JOB_ROUTER_DEFAULTS) [set_foo = 1;]
#
MERGE_JOB_ROUTER_DEFAULT_ADS=True
#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# Warning: JOB_ROUTER_DEFAULTS, JOB_ROUTER_ENTRIES, JOB_ROUTER_ENTRIES_CMD, and
#          JOB_ROUTER_ENTRIES_FILE are deprecated and will be removed for V24 of
#          the HTCondor Software Suite. New configuration syntax for the job router is defined using
#          JOB_ROUTER_ROUTE_NAMES and JOB_ROUTER_ROUTE_<name>. For new syntax example visit:
# https://htcondor.readthedocs.io/en/latest/grid-computing/job-router.html#an-example-configuration
#   Note: The removal will occur during the lifetime of the HTCondor V23 feature series.
#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
JOB_ROUTER_DEFAULTS = $(JOB_ROUTER_DEFAULTS_GENERATED)

# Disable JOB_ROUTER_DEFAULTS + JOB_ROUTER_ENTRIES by default.
# These represent the old route syntax, which will be removed for
# HTCondor V24.
JOB_ROUTER_USE_DEPRECATED_ROUTER_ENTRIES = False


#################################
# Default Job Router Transforms #
#################################

JOB_ROUTER_PRE_ROUTE_TRANSFORM_NAMES = Base Cleanup OrigRequests
JOB_ROUTER_POST_ROUTE_TRANSFORM_NAMES = Cpus Gpus Memory Queue BatchRuntime CERequirements OnExitHold

JOB_ROUTER_TRANSFORM_Base @=jrt
    # Always set the following routed job attributes
    SET RoutedJob                  True
    # Older Condor-C jobs don't add this requirement for GPU jobs and
    # startds don't add a check if GPU detection is not enabled.
    EVALMACRO test_requirements_true unparse(Requirements)=="true"
    if $(test_requirements_true)
        SET Requirements           (RequestGpus?:0) >= (TARGET.Gpus?:0)
    endif

@jrt


JOB_ROUTER_TRANSFORM_Cleanup @=jrt
    # If the batch condor job is removed then the CE will resubmit the
    # job and we want to void that
    DELETE PeriodicRemove
    DELETE TotalSubmitProcs
@jrt


JOB_ROUTER_TRANSFORM_OrigRequests @=jrt
    # The AuthToken* attributes can't be sent on to the destination schedd, so we rename them here
    RENAME /^AuthToken.*$/          orig_\0
    # Copy original, incoming job attributes for use in post transforms
    COPY /^OnExitHold.*$/          orig_\0
    COPY BatchRuntime              orig_BatchRuntime
    COPY environment               orig_environment
    # the BLAHP uses WholeNodes=true for the same thing that we use WantWholeNode=true
    COPY WantWholeNode             WholeNodes

    # Support whole node job requests against HTCondor pools if the source job specifies 'WantWholeNode = True'
    # 'if' can't handle complex expressions yet so we evaluate it here for use in post-transforms
    EVALMACRO test_want_whole_node $(MY.WantWholeNode:False)
@jrt


JOB_ROUTER_TRANSFORM_Cpus @=jrt
    # Outside of the HTCondor WholeNodeJobs case, set RequestCpus to one of the following, in order:
    # 1. 'xcount' from the source job
    # 2. RequestCpus from the source job, but only if > 1
    # 3. default_xcount from the job route
    # 4. 1

    if defined MY.xcount
        EVALSET RequestCpus xcount
    else
        EVALMACRO test_RequestCpus ($(MY.RequestCpus:0)) > 1
        if $(test_RequestCpus)
            # RequestCpus already correct
        else
            EVALSET RequestCpus $(default_xcount:1)
        endif
    endif

    # the old-style transforms ignored RequestCPUs for... reasons? when setting these. we do the same here.
    EVALSET remote_SMPGranularity  xcount ?: ($(default_xcount:1))
    COPY    remote_SMPGranularity  remote_NodeNumber

    SET JobIsRunning           (JobStatus =!= 1) && (JobStatus =!= 5)

    if $(test_want_whole_node)
        SET JOB_GLIDEIN_Cpus       "$$([TotalCpus ?: JobCpus])"
        # MATCH_EXP_JOB_GLIDEIN_Cpus is based on the value of JOB_GLIDEIN_Cpus once the routed job is matched to an
        # HTCondor slot
        SET GlideinCpusIsGood      int(MATCH_EXP_JOB_GLIDEIN_Cpus ?: "0") isnt error
        # Also used by JobGpus and JobMemory
        SET JobIsRunning           $(MY.JobIsRunning) && GlideinCpusIsGood
        COPY RequestCpus           OriginalCpus
        SET JobCpus                JobIsRunning ? int(MATCH_EXP_JOB_GLIDEIN_Cpus) : OriginalCpus
        SET RequestCpus            TARGET.TotalCpus ?: JobCpus
    endif


@jrt


JOB_ROUTER_TRANSFORM_Gpus @=jrt
    # Request GPUs for whole node jobs (HTCONDOR-103)
    # If a whole node job requests GPUs and is matched to a machine with GPUs then set the job's RequestGPUs to all the
    # GPUs on that machine
    REQUIREMENTS RequestGpus isnt undefined
    if $(test_want_whole_node)
        SET JOB_GLIDEIN_GPUs       "$$([TotalGPUs ?: JobGPUs])"
        # MATCH_EXP_JOB_GLIDEIN_GPUs is based on the value of JOB_GLIDEIN_GPUs once the routed job is matched to an
        # HTCondor slot
        SET GlideinGPUsIsGood      int(MATCH_EXP_JOB_GLIDEIN_GPUs ?: "0") isnt error
        COPY RequestGPUs           OriginalGPUs
        SET JobGPUs                JobIsRunning ? int(MATCH_EXP_JOB_GLIDEIN_GPUs) : OriginalGPUs
        SET RequestGPUs            ((TARGET.TotalGPUs ?: 0) > 0) ? TotalGPUs: JobGPUs
    endif
@jrt


JOB_ROUTER_TRANSFORM_Memory @=jrt
    # Outside of the HTCondor WholeNodeJobs case, set RequestMemory to one of the following, in order:
    # 1. 'maxMemory' from the source job if it's defined
    # 2. default_MaxMemory from the job route
    # 3. 2000
    # Note that if the route does the condor thing and sets RequestMemory, this transform will stomp on that

    EVALSET RequestMemory maxMemory ?: ($(default_maxMemory:2000))

    # set JobMemory so we have a common attribute between regular and WholeNode jobs
    # that can be queried even when the job is not running
    SET JobMemory RequestMemory

    if $(test_want_whole_node)
        SET JOB_GLIDEIN_Memory     "$$(TotalMemory:0)"
        # Save RequestMemory to OriginalMemory for later use, 
        # and if OriginalMemory is needed, remote_OriginalMemory is needed also because blahp
        COPY RequestMemory OriginalMemory
        COPY RequestMemory remote_OriginalMemory
        SET JobMemory              JobIsRunning ? int(MATCH_EXP_JOB_GLIDEIN_Memory)*95/100 : OriginalMemory
        SET RequestMemory          TARGET.TotalMemory*95/100 ?: JobMemory
    endif

@jrt


JOB_ROUTER_TRANSFORM_Queue @=jrt
    # Set the remote batch queue to one of the following, in order:
    # 1. 'batch_queue' from the source job
    # 2. 'queue' from the source job
    # 3. 'default_queue' from the route
    # 4. Empty string
    if defined MY.batch_queue
       EVALSET remote_queue MY.batch_queue
    elif defined MY.queue
       EVALSET remote_queue MY.queue
    else
       EVALSET remote_queue "$(default_queue)"
    endif
@jrt


JOB_ROUTER_TRANSFORM_BatchRuntime @=jrt
    # 'BatchRuntime' is in seconds but admins configure 'default_maxWallTime' and 'ROUTED_JOB_MAX_TIME' and remote
    # submitters set 'maxWallTime' in minutes. Remote submitters set 'BatchRuntime' in seconds.
    # Set the remote batch runtime used by non-HTCondor batch systems to one of the following, in order:
    # 1. 'maxWalltime' (minutes) from the source job
    # 2. 'BatchRuntime' (seconds) from the source job
    # 3. 'default_maxWallTime' (minutes) from the route
    # 4. 'ROUTED_JOB_MAX_TIME' (minutes) from the config
    if defined MY.maxWallTime
        EVALSET BatchRuntime 60*maxWallTime
    elif defined MY.orig_BatchRuntime
        # do nothing, BatchRuntime already set
    elif defined default_maxWallTime
        # default_maxWallTime can be an attribute reference here
        EVALSET BatchRuntime 60*$(default_maxWallTime)
    else
        EVALSET BatchRuntime 60*$(ROUTED_JOB_MAX_TIME:4320)
    endif
@jrt


JOB_ROUTER_TRANSFORM_CERequirements @=jrt
    SET CondorCE 1
    if defined MY.default_CERequirements
        SET CERequirements "$(MY.default_CERequirements),CondorCE"
    else
        SET CERequirements "CondorCE"
    endif
@jrt


JOB_ROUTER_TRANSFORM_OnExitHold @=jrt
    # transform only if the route specifed a minimum walltime
    REQUIREMENTS minWalltime isnt undefined

    SET CondorCE_OnExitHold            RemoteWallClockTime < 60*minWallTime
    SET CondorCE_OnExitHoldSubcode     IfThenElse(CondorCE_OnExitHold ?: False, 42, 1)
    SET CondorCE_OnExitHoldReason      IfThenElse(CondorCE_OnExitHold ?: False, \
                                         "The job's wall clock time is less than the minimum specified by the job ($(MY.minWalltime)) min", \
                                         "Job held for unknown reason.")
    if defined MY.orig_OnExitHold
        SET OnExitHold                  (orig_OnExitHold ?: False) || CondorCE_OnExitHold
        SET OnExitHoldSubcode           IfThenElse(orig_OnExitHold ?: False, orig_OnExitHoldSubcode, CondorCE_OnExitHoldSubcode)
        SET OnExitHoldReason            IfThenElse(orig_OnExitHold ?: False, orig_OnExitHoldReason, CondorCE_OnExitHoldReason)
    else
        SET OnExitHold                  CondorCE_OnExitHold
        SET OnExitHoldSubcode           CondorCE_OnExitHoldSubcode
        SET OnExitHoldReason            CondorCE_OnExitHoldReason
    endif
@jrt
